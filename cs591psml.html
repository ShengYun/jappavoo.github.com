<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<title>CS591: Programmable Smart Machines</title>
</head>
<body>
<h1>CAS CS 591, Programmable Smart Machines</h1>
<h2>Schedule</h2>
<p>Tue, Thu --  9:30pm-11:00pm</p>
<h2>Course Outline</h2>
<p>
  A longstanding goal in computer science has been
  to build machines capable of
  automatically improving based on their experience and size.
  In his 1968 paper,
  <a href="http://dx.doi.org/10.1038/218019a0">'Memo' Functions and
  Machine Learning</a> (Nature, Apr. '68),
  Donald Michie challenged computer scientists with the
  following goal:
<blockquote>
  "It would be useful if computers could learn from experience and
  thus automatically improve the efficiency of their own programs
  during execution... When I write a clumsy program for a contemporary
  computer a thousand runs on the machine do not re-educate my
  handiwork.  On every execution, each time-wasting blemish and
  crudity, each needless test and redundant evaluation, is
  meticulously reproduced."
</blockquote>

  Over the past several years the instructors of this course
  have been developing the concept of
  Programmable Smart Machines (PSMs): hybrid computing systems whose
  output is as programmed but which transparently learn and automatically
  improve their operation.  Both from the theoretical and practical 
  point of view, our work attempts to side-step the traditional bottlenecks
  associated with the von Neumann architecture while preserving its
  programming model.  
  In this course we will look at a cross section of the material
  that has informed our work, encompassing
  applied and theoretical
  topics.  Topics will include material from
  complexity theory, computer architecture,
  operating systems, machine learning and  biologically
  inspired computation.  A fundmental aspect of this course is
  to identify and clearly state open questions in this area of work.
</p>
<p>
  The course will be predominantly structured as a seminar in which
  each week we will be looking at one or two research papers.
  You will be required to submit weekly reviews and actively
  participate in the discussions.   Each student will conduct and a
  term long project.
</p> 

<h2>Instructors</h2>

<p>Jonathan Appavoo:
<a href="mailto:jappavoo@bu.edu">jappavoo@bu.edu</a>
<p>Steve Homer:
<a href="mailto:homer@cs.bu.edu">homer@cs.bu.edu</a>
<p>Amos Waterland:
<a href="mailto:apw@seas.harvard.edu">apw@seas.harvard.edu</a>

<h2>Target audience</h2>
<p>This course is targeted towards
  graduate and advanced undergraduate students.
  We encourage enrollment by both
  theory and systems students, especially
  those of you willing to push
  the boundaries of what you have been thinking about.
  You are encouraged to incorporate your personal interests and
  background into the class material.
</p>
<h2>Prerequisites</h2>
<p>
  Students taking this class must have permision from the
instructors, be a either a senior or graduate student,
and be proficient in the core material of systems and theory.
</p>
<h2>Workload</h2>
<p>
  Each week we will be covering on average one to two research papers that
  you will be expected to read, review and discuss.  These papers
  will likely require that you find and read additional material
  as necessary to ensure your comprehension.  Do not underestimate
  the amount of work this can be.  You will be required to submit
  a written review of the papers prior to class.  You will also
  be expected to actively participate in the in-class discussion.
  Each student is expected to lead one of the class discussions
  by summarizing the paper and seeding conversation with questions
  and observations from the paper.  
</p>
  
<p>In addition to the weekly paper reviews there will be a final project
in which you will explore in detail an aspect of Programmable
Smart Machines.  Projects can range from a theoretical
exploration to an applied experimental evaluation.   The topic of your
project must be approved by the instructors.
You will be expected
to present a poster about your project and to submit a brief
written report by the end of the term.  As part of the project you 
will be expected to establish in conjunction with the
instructors the goals and criteria for its evalution.  Each week you will
provide a brief update on the progess of your project.
</p>

<p>
The project is due by the end of the lecture period. The project presentations
will be given in the form of a final poster during the scheduled final
exam slot.
</p>
<p>Students are expected to work individually on the weekly reviews.
With instructor approval the final project may be done in groups of
up to
two. There will be no final exam other than the poster presentations.  </p>

<h2>Grading</h2>

Reviews, Discussions, paper presentation: 40%
<p>
Project Poster and Report: 60%

<h2>Tentative schedule</h2>

<table border="1" style="background-color:#FFFFCC;border-collapse:collapse;border:1px solid #FFCC00;color:#000000;width:100%" cellpadding="3" cellspacing="3">
	<tr>
		<td><b>Date</b></td>
		<td><b>Description</b></td>
		<td><b>Links</b></td>
		<td><b>Deadlines</b></td>
	</tr>
<tr><td>01/20</td><td>Class  1: Overview and Introductions</td><td></td></tr>
<tr><td>01/22</td><td>Class  2: ASC Presentation & Discussion</td>
<td><a href="http://people.seas.harvard.edu/~apw/papers/asplos14.pdf">
  1: ASC: Automatically Scalable Computation<br>
  <a
	href="http://www.cs.bu.edu/~jappavoo/Resources/591psml/review-copy.pdf">2: ieee draft</a>
</td></tr>
<tr><td>01/27</td><td>Class  3: ASC Tutorial</td>
<td>
  <a href="http://people.seas.harvard.edu/~apw/papers/asplos14.pdf">1: 
  ASC: Automatically Scalable Computation<br>
  <a
	href="http://www.cs.bu.edu/~jappavoo/Resources/591psml/review-copy.pdf">2: ieee draft</a>
</td></tr>
<tr><td>01/29</td><td>Class  4: Discussion of Projects and Papers</td>
<td>
</td>
<td> Instructors will update lists by this point. You must be ready to
  discuss your interests.
</tr>
<tr><td>02/03</td><td>Class  5: History and Foundations</td>
<td>
   <a href="http://www.virtualtravelog.net/wp/wp-content/media/2003-08-TheFirstDraft.pdf">
  1: First Draft of a Report on the EDVAC</a>
</td></tr>
<tr><td>02/05</td><td>Class  6: History and Foundations</td>
<td>
  <a
	href="http://www.cs.bu.edu/~jappavoo/Resources/591psml/McCulloch.and.Pitts.pdf">1: A LOGICAL CALCULUS OF THE IDEAS IMMANENT IN NERVOUS ACTIVITY</a>
</td>
<td>Pick Project and Paper</td>
</tr>
<tr><td>02/10</td><td>Class  7: History and Foundations</td>
<td>
  <a href="http://www.cs.utexas.edu/~hunt/research/hash-cons/hash-cons-papers/michie-memo-nature-1968.pdf">
  1: "Memo" functions and Machine Learning</a><br>
   <a href="http://www.wisdom.weizmann.ac.il/~oded/cc-sum.html">2:
	Advice, Space Complexity and Approximate Counting Lecture
	Notes on Complexity Theory (Chapter 8 and depends on 1 and 2)
        by Oded Goldreich</a>
</td></tr>
<tr><td>02/12</td><td>Class  8: History and
	Foundations</td>
<td>
  <a
	href="http://www.cs.bu.edu/~jappavoo/Resources/591psml/10.1.1.335.3398.pdf">1: THE PERCEPTRON: A PROBABILISTIC MODEL FOR INFORMATION
	STORAGE AND ORGANIZATION IN THE BRAIN</a>
</td></tr>	
<tr><td>02/19</td><td>Class  9: History and Foundations</td>
<td>
  <a
	href="http://www.cs.bu.edu/~jappavoo/Resources/591psml/10.1.1.161.9762.pdf">1: Neuromorphic Electronic Systems</a></br>
  <a
	href="http://www.cs.bu.edu/~jappavoo/Resources/591psml/p13-monroe.pdf">2: Neuromorphic Computing Gets Ready for the (Really) Big
	Time</a> Follow up on references</br>
</td>
<td>One Page Project Topic Proposal Due</td>
</tr>
<tr><td>02/24</td><td>Class  10: TBA </td><td></td></tr>
<tr><td>02/26</td><td>Class  11: TBA </td><td></td></tr>
<tr><td>03/03</td><td>Class  12: TBA  </td><td></td></tr>
<tr><td>03/05</td><td>Class  13: TBA </td><td></td></tr>
<tr><td>03/17</td><td>Class  14: TBA  </td><td></td><td>Three Page Project
	Overview Due</tr>
<tr><td>03/19</td><td>Class  15: TBA </td><td></td></tr>
<tr><td>03/24</td><td>Class  16: TBA </td><td></td></tr>
<tr><td>03/26</td><td>Class  17: TBA </td><td></td></tr>
<tr><td>03/31</td><td>Class  18: TBA </td><td></td></tr>
<tr><td>04/02</td><td>Class  19: TBA </td><td></td></tr>
<tr><td>04/07</td><td>Class  20: TBA </td><td></td></tr>
<tr><td>04/09</td><td>Class  21: TBA </td><td></td></tr>
<tr><td>04/14</td><td>Class  22: TBA </td><td></td></tr>
<tr><td>04/16</td><td>Class  23: TBA </td><td></td></tr>
<tr><td>04/21</td><td>Class  24: TBA </td><td></td></tr>
<tr><td>04/23</td><td>Class  25: TBA </td><td></td><td>Poster Outline Due</td</tr>
<tr><td>04/28</td><td>Class  26: TBA </td><td></td></tr>
<tr><td>04/30</td><td>Class  27: TBA </td><td></td><td>Project
	Report Due</td</tr>
<tr><td>TBA</td><td>EXAM: POSTER SESSION</td><td></td>></tr>
</table>

<h3> List of some possible papers: </h3>
This list will be extended in the first few weeks of class
based on students back grounds and interests

<ol>
 <li>
 <a href="http://www.cs.utexas.edu/~hunt/research/hash-cons/hash-cons-papers/michie-memo-nature-1968.pdf">
  "Memo" functions and Machine Learning</a><br>
  D. Michie<br>
  Nature, 1968
 </li>

 <li>
 <a href="http://www.virtualtravelog.net/wp/wp-content/media/2003-08-TheFirstDraft.pdf">
  First Draft of a Report on the EDVAC</a><br>
  J. von Neumann<br>
  U.S. Army Ordnance Department Report, 1945
 </li>

 <li>
 <a href="http://wiki.cs.unm.edu/ssl/data/media/papers/massalin95threads.pdf">
  Threads and Input/Output in the Synthesis Kernel</a><br>
  H. Massalin, C. Pu<br>
  SOSP, 1995
 </li>

 <li>
 <a href="https://www.complang.tuwien.ac.at/andi/bala.pdf">
  Dynamo: A Transparent Dynamic Optimization System</a><br>
  V. Bala, E. Duesterwald, S. Banerjia<br>
  PLDI, 2000
 </li>

 <li>
 <a href="http://people.seas.harvard.edu/~apw/papers/asplos14.pdf">
  ASC: Automatically Scalable Computation</a><br>
  A. Waterland, E. Angelino, R.P. Adams, J. Appavoo, M. Seltzer<br>
  ASPLOS, 2014
 </li>

 <li>
 <a href="http://people.seas.harvard.edu/~apw/papers/angelino-uai-2014.pdf">
  Accelerating MCMC via Parallel Predictive Prefetching</a><br>
  E. Angelino, E. Kohler, A. Waterland, M. Seltzer, R.P. Adams<br>
  UAI, 2014
 </li>

 <li>
 <a href="http://homes.cs.washington.edu/~luisceze/publications/analognpu-isca14.pdf">General-Purpose Code Acceleration with Limited-Precision Analog Computation</a><br>
  Ceze et al.<br>
  ISCA, 2014
 </li>

 <li>
 <a href="http://web.mit.edu/6.976/www/handout/valiant2.pdf">
  A bridging model for parallel computation</a><br>
  L. Valiant<br>
  CACM, 1990
 </li>

 <li>
  <a href="https://homes.cs.washington.edu/~ruzzo/papers/limits.pdf">
   Limits to Parallel Computation</a> (Chapter 1)<br>
  R. Greenlaw<br>
  1991
 </li>

 <li>
  <a href="https://homes.cs.washington.edu/~ruzzo/papers/limits.pdf">
   Limits to Parallel Computation</a> (Chapter 2)<br>
  R. Greenlaw<br>
  1991
 </li>

 <li>
 <a href="http://theoryofcomputing.org/articles/gs001/gs001.pdf">
  A Brief Introduction to Fourier Analysis on the Boolean Cube</a><br>
  R. de Wolf<br>
  TGCS, 2008
 </li>

</ol>
<h3> Project Ideas </h3>
This list will be extended in the first few weeks of class
based on students back grounds and interests.

<h2>Collaboration and Academic Honesty</h2>

<p>
All course participants must adhere to the
CAS Academic Conduct Code.  Instances of academic
dishonesty will be reported to the
academic conduct committee.
</p>

</body>
</html>
